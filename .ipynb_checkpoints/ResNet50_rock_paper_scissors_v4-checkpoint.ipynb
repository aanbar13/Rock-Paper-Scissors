{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper', 'rock', 'scissors']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'Data_rock_paper_scissor_KAGGLE/Rock-Paper-Scissors-2/'\n",
    "print(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paper', 'rock', 'scissors']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "Name=['paper','rock','scissors']\n",
    "print(Name)\n",
    "print(len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping={\"paper\":0,\"rock\":1,\"scissors\":2}\n",
    "reverse_mapping={0:'paper',1:'rock',2:'scissors'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX=[]\n",
    "dataY0=[]\n",
    "count=0\n",
    "for name in Name:\n",
    "    path=os.path.join(data_dir,name)\n",
    "    for im in os.listdir(path):\n",
    "        image=cv2.imread(os.path.join(path,im))\n",
    "        if type(image)==np.ndarray and image.shape[0]>10 and image.shape[1]>10:\n",
    "            image3=cv2.resize(image,dsize=(100,100),interpolation=cv2.INTER_CUBIC)\n",
    "            dataX+=[image3]\n",
    "            dataY0+=[count]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX=np.array(dataX)\n",
    "dataY0=np.array(dataY0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=len(dataX)\n",
    "M=list(range(m))\n",
    "random.seed(2021)\n",
    "random.shuffle(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX=dataX[M[0:(m//4)*3]]\n",
    "trainY0=dataY0[M[0:(m//4)*3]]\n",
    "testX=dataX[M[(m//4)*3:]]\n",
    "testY0=dataY0[M[(m//4)*3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=to_categorical(trainY0)\n",
    "trainY=np.array(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx,testx,trainy,testy=train_test_split(trainX,trainY,test_size=0.2,random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 100, 100, 3)\n",
      "(329, 100, 100, 3)\n",
      "(1312, 3)\n",
      "(329, 3)\n"
     ]
    }
   ],
   "source": [
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                            vertical_flip=True,rotation_range=20,zoom_range=0.2,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.ResNet50(input_shape=(100,100,3),\n",
    "                                                        include_top=False,\n",
    "                                                        weights='imagenet',\n",
    "                                                        pooling='avg')\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pretrained_model.input\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 55s 1s/step - loss: 0.4269 - accuracy: 0.8567 - val_loss: 0.0879 - val_accuracy: 0.9696\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 35s 862ms/step - loss: 0.1032 - accuracy: 0.9604 - val_loss: 0.0420 - val_accuracy: 0.9848\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 32s 774ms/step - loss: 0.1210 - accuracy: 0.9581 - val_loss: 0.0178 - val_accuracy: 0.9970\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 31s 758ms/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 0.0228 - val_accuracy: 0.9970\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 32s 779ms/step - loss: 0.0657 - accuracy: 0.9809 - val_loss: 0.0178 - val_accuracy: 0.9939\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 31s 758ms/step - loss: 0.0535 - accuracy: 0.9809 - val_loss: 0.0767 - val_accuracy: 0.9726\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 32s 782ms/step - loss: 0.0568 - accuracy: 0.9802 - val_loss: 0.0308 - val_accuracy: 0.9909\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 32s 783ms/step - loss: 0.0519 - accuracy: 0.9825 - val_loss: 0.0075 - val_accuracy: 0.9970\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 32s 768ms/step - loss: 0.0379 - accuracy: 0.9832 - val_loss: 0.0068 - val_accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 31s 764ms/step - loss: 0.0547 - accuracy: 0.9794 - val_loss: 0.0213 - val_accuracy: 0.9939\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "his=model.fit(datagen.flow(trainx,trainy,batch_size=32),validation_data=(testx,testy),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('Data_rock_paper_scissor_KAGGLE/RPS_detectionModel_v4.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
